"""
Блок 5: ML Base
Задание 1: Пони тоже кони

Вас просят разработать модель, классифицирующую лошадок и пони.
Вместо разработки вы нашли на GitHub две интересные модели и после прогона на ваших данных
одна из них показала ROC-AUC=0.7, а другая ROC-AUC=0.1.

Какую модель вы возьмете для дальнейшей работы и что будете с ней делать?

Ответ написать развернуто, но кратко, например: "первую, отниму от метрики 0.1 для корректировки точности"
"""
"""
Посмотрела
- ROC-AUC = 1.0: идеальная модель
- ROC-AUC = 0.7: приемлемая модель, но не отличная
- ROC-AUC = 0.1: модель работает ХУЖЕ случайного угадывания

Модель с ROC-AUC = 0.1:
- Очень плохой результат
- Модель делает предсказания хуже случайных
- Или модель не обучена на правильных данных
- Или есть серьезные проблемы с данными/предобработкой

Модель с ROC-AUC = 0.7:
- Это приемлемый результат
- Модель показывает некоторую способность к разделению классов
- Но есть место для улучшения

Выбираю,из двух, модель с ROC-AUC = 0.7, потому что:
1. Она показывает положительную способность к классификации
2. Модель с ROC-AUC = 0.1 работает хуже случайного угадывания

Мои действия:
Работа с моделью ROC-AUC = 0.7:
   - Использовать её, как базовую модель
   - Попытаться улучшить через:
     * Дополнительное обучение на Ваших данных (fine-tuning)
     * Ансамблирование с другими моделями("мудрость толпы")
     * Улучшение признаков
     * Балансировку классов
   - Проанализировать ошибки модели
  """
answer = """
Выбираю модель с ROC-AUC=0.7 для дальнейшей работы.

Модель с ROC-AUC=0.1 работает хуже случайного угадывания (0.5), что указывает на серьезные проблемы:
возможно, классы перепутаны, модель не обучена на подходящих данных, или есть ошибки в применении.

С моделью ROC-AUC=0.7 буду:
1. Использовать как базовую модель
2. Проводить fine-tuning на моих данных
3. Анализировать ошибки через confusion matrix
4. Улучшать через feature engineering и балансировку классов
5. Рассмотреть ансамблирование с другими моделями для повышения метрики
"""

print("=" * 80)
print("АНАЛИЗ МОДЕЛЕЙ: Лошади и пони")
print("=" * 80)
print("\nМодель 1: ROC-AUC = 0.7")
print("Модель 2: ROC-AUC = 0.1\n")

print("ОТВЕТ:")
print(answer)

print("\n" + "=" * 80)
print("ОБОСНОВАНИЕ:")
print("=" * 80)
print("- ROC-AUC = 0.1 означает, что модель работает ХУЖЕ случайного угадывания")
print("- ROC-AUC = 0.7 показывает приемлемую способность к классификации")
print("- Модель с 0.1 может иметь перепутанные классы или серьезные проблемы")
print("- Модель с 0.7 можно улучшить через fine-tuning и feature engineering")

"""
check
АНАЛИЗ МОДЕЛЕЙ: Лошади и пони
================================================================================

Модель 1: ROC-AUC = 0.7
Модель 2: ROC-AUC = 0.1

ОТВЕТ:

Выбираю модель с ROC-AUC=0.7 для дальнейшей работы.

Модель с ROC-AUC=0.1 работает хуже случайного угадывания (0.5), что указывает на серьезные проблемы:
возможно, классы перепутаны, модель не обучена на подходящих данных, или есть ошибки в применении.

С моделью ROC-AUC=0.7 буду:
1. Использовать как базовую модель
2. Проводить fine-tuning на моих данных
3. Анализировать ошибки через confusion matrix
4. Улучшать через feature engineering и балансировку классов
5. Рассмотреть ансамблирование с другими моделями для повышения метрики


================================================================================
ОБОСНОВАНИЕ:
================================================================================
- ROC-AUC = 0.1 означает, что модель работает ХУЖЕ случайного угадывания
- ROC-AUC = 0.7 показывает приемлемую способность к классификации
- Модель с 0.1 может иметь перепутанные классы или серьезные проблемы
- Модель с 0.7 можно улучшить через fine-tuning и feature engineering
"""

""
Задание 2: Ручной счёт ROC_AUC

Классификатор выдал следующие прогнозируемые метки класса и вероятности принадлежности к классу "1".
На основе полученных данных рассчитайте метрику ROC_AUC. Тезисно описать ход решения.

Ответ округлить до сотых, например: 4,12

Истинная метка класса | Порог классификации (0.6) | Оценка вероятности
1                     | 1                          | 0.95
0                     | 1                          | 0.9
1                     | 1                          | 0.85
0                     | 1                          | 0.8
1                     | 1                          | 0.75
1                     | 1                          | 0.7
1                     | 1                          | 0.65
1                     | 1                          | 0.6
0                     | 0                          | 0.55
0                     | 0                          | 0.5
0                     | 0                          | 0.45
1                     | 0                          | 0.4
0                     | 0                          | 0.35
0                     | 0                          | 0.3
0                     | 0                          | 0.25
"""

import numpy as np
def calculate_roc_auc(y_true, y_scores):
    """
    Вычисляем ROC-AUC вручную.
        
    Алгоритм:
    1. Сортируем данные по убыванию вероятностей
    2. Для каждого порога вычисляем TPR и FPR
    3. Строим ROC-кривую
    4. Вычисляем площадь под кривой (AUC) методом трапеций
    
    """
    # Сортируем, инициализируем переменные
    sorted_indices = np.argsort(y_scores)[::-1]
    y_true_sorted = y_true[sorted_indices]
    y_scores_sorted = y_scores[sorted_indices]    
    n_pos = np.sum(y_true == 1)
    n_neg = np.sum(y_true == 0)    
    if n_pos == 0 or n_neg == 0:
        return 0.5    
    tpr = [0.0]  # True Positive Rate
    fpr = [0.0]  # False Positive Rate
    tp = 0
    fp = 0
    # Вычисляем TPR и FPR для каждого порога
    for i in range(len(y_true_sorted)):
        if y_true_sorted[i] == 1:
            tp += 1
        else:
            fp += 1
        
        tpr.append(tp / n_pos)
        fpr.append(fp / n_neg)    
    # Вычисляем AUC методом трапеций
    auc = 0.0
    for i in range(1, len(fpr)):
        auc += (fpr[i] - fpr[i-1]) * (tpr[i] + tpr[i-1]) / 2.0
    
    return auc


# Берем данные из задания
y_true = np.array([1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0])
y_scores = np.array([0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25])

print("=" * 80)
print("РУЧНОЙ РАСЧЕТ ROC-AUC")
print("=" * 80)

print("\nХОД РЕШЕНИЯ:")
print("1. Сортируем данные по убыванию вероятностей")
print("2. Для каждого порога вычисляем:")
print("2. Для каждого порога вычисляем:")
print("   - TPR (True Positive Rate) = TP / (TP + FN)")
print("   - FPR (False Positive Rate) = FP / (FP + TN)")
print("3. Строим ROC-кривую (FPR по оси X, TPR по оси Y)")
print("4. Вычисляем площадь под кривой (AUC) методом трапеций\n")

# Количество классов
n_pos = np.sum(y_true == 1)
n_neg = np.sum(y_true == 0)
print(f"Количество положительных примеров (класс 1): {n_pos}")
print(f"Количество отрицательных примеров (класс 0): {n_neg}\n")

# Сортируем по убыванию вероятностей
sorted_indices = np.argsort(y_scores)[::-1]
y_true_sorted = y_true[sorted_indices]
y_scores_sorted = y_scores[sorted_indices]
print("Отсортированные данные (по убыванию вероятности):")
print("Вероятность | Истинный класс")
print("-" * 40)
for i in range(len(y_scores_sorted)):
    print(f"{y_scores_sorted[i]:.2f}        | {y_true_sorted[i]}")

# Вычисляем ROC-AUC
auc = calculate_roc_auc(y_true, y_scores)

print("\n" + "=" * 80)
print(f"ROC-AUC = {auc:.2f}")
print("=" * 80)

# Детальный расчет для понимания
print("\nДетальный расчет:")
print("Порог | TP | FP | TN | FN | TPR    | FPR")
print("-" * 60)
tp = 0
fp = 0
tn = n_neg
fn = n_pos
for i in range(len(y_true_sorted)):
    threshold = y_scores_sorted[i]
    if y_true_sorted[i] == 1:
        tp += 1
        fn -= 1
    else:
        fp += 1
        tn -= 1
    
    tpr_val = tp / n_pos if n_pos > 0 else 0
    fpr_val = fp / n_neg if n_neg > 0 else 0
    
    print(f"{threshold:.2f} | {tp:2d} | {fp:2d} | {tn:2d} | {fn:2d} | {tpr_val:.3f} | {fpr_val:.3f}")
    print(f"\nИтоговый ROC-AUC: {auc:.2f}")
"""
check
РУЧНОЙ РАСЧЕТ ROC-AUC
================================================================================

ХОД РЕШЕНИЯ:
1. Сортируем данные по убыванию вероятностей
2. Для каждого порога вычисляем:
2. Для каждого порога вычисляем:
   - TPR (True Positive Rate) = TP / (TP + FN)
   - FPR (False Positive Rate) = FP / (FP + TN)
3. Строим ROC-кривую (FPR по оси X, TPR по оси Y)
4. Вычисляем площадь под кривой (AUC) методом трапеций

Количество положительных примеров (класс 1): 7
Количество отрицательных примеров (класс 0): 8

Отсортированные данные (по убыванию вероятности):
Вероятность | Истинный класс
----------------------------------------
0.95        | 1
0.90        | 0
0.85        | 1
0.80        | 0
0.75        | 1
0.70        | 1
0.65        | 1
0.60        | 1
0.55        | 0
0.50        | 0
0.45        | 0
0.40        | 1
0.35        | 0
0.30        | 0
0.25        | 0

================================================================================
ROC-AUC = 0.75
================================================================================

Детальный расчет:
Порог | TP | FP | TN | FN | TPR    | FPR
------------------------------------------------------------
0.95 |  1 |  0 |  8 |  6 | 0.143 | 0.000

Итоговый ROC-AUC: 0.75
0.90 |  1 |  1 |  7 |  6 | 0.143 | 0.125

Итоговый ROC-AUC: 0.75
0.85 |  2 |  1 |  7 |  5 | 0.286 | 0.125

Итоговый ROC-AUC: 0.75
0.80 |  2 |  2 |  6 |  5 | 0.286 | 0.250

Итоговый ROC-AUC: 0.75
0.75 |  3 |  2 |  6 |  4 | 0.429 | 0.250

Итоговый ROC-AUC: 0.75
0.70 |  4 |  2 |  6 |  3 | 0.571 | 0.250

Итоговый ROC-AUC: 0.75
0.65 |  5 |  2 |  6 |  2 | 0.714 | 0.250

Итоговый ROC-AUC: 0.75
0.60 |  6 |  2 |  6 |  1 | 0.857 | 0.250

Итоговый ROC-AUC: 0.75
0.55 |  6 |  3 |  5 |  1 | 0.857 | 0.375

Итоговый ROC-AUC: 0.75
0.50 |  6 |  4 |  4 |  1 | 0.857 | 0.500

Итоговый ROC-AUC: 0.75
0.45 |  6 |  5 |  3 |  1 | 0.857 | 0.625

Итоговый ROC-AUC: 0.75
0.40 |  7 |  5 |  3 |  0 | 1.000 | 0.625

Итоговый ROC-AUC: 0.75
0.35 |  7 |  6 |  2 |  0 | 1.000 | 0.750

Итоговый ROC-AUC: 0.75
0.30 |  7 |  7 |  1 |  0 | 1.000 | 0.875

Итоговый ROC-AUC: 0.75
0.25 |  7 |  8 |  0 |  0 | 1.000 | 1.000

Итоговый ROC-AUC: 0.75
"""

"""
Задание 3: Ручной счёт корреляции

Рассчитайте линейную корреляцию Пирсона на основе данных.
Какой вывод можно сделать на основе полученного результата?
Можно ли утверждать, что существует причинно-следственная связь между количеством чашек кофе,
выпитых студентами в течение экзаменационного дня, и их итоговым баллом за экзамен?

Ответ округлить до сотых, например: 4,12

Число выпитых чашек кофе | Балл за экзамен
1                        | 85
1                        | 88
2                        | 79
2                        | 81
2                        | 84
2                        | 65
3                        | 67
3                        | 58
3                        | 76
4                        | 49
"""
import numpy as np
import math

def pearson_correlation(x, y):
    """
      Вычисляем коэффициент корреляции Пирсона.
    
    Формула: r = Σ((xi - x̄)(yi - ȳ)) / √(Σ(xi - x̄)² * Σ(yi - ȳ)²)
    """
    n = len(x)
    
    # Средние значения
    mean_x = np.mean(x)
    mean_y = np.mean(y)
    
    # Числитель: Σ((xi - x̄)(yi - ȳ))
    numerator = np.sum((x - mean_x) * (y - mean_y))
    
    # Знаменатель: √(Σ(xi - x̄)² * Σ(yi - ȳ)²)
    sum_sq_diff_x = np.sum((x - mean_x) ** 2)
    sum_sq_diff_y = np.sum((y - mean_y) ** 2)
    denominator = math.sqrt(sum_sq_diff_x * sum_sq_diff_y)
    
    if denominator == 0:
        return 0.0    
    correlation = numerator / denominator
    return correlation
    
# Берем данные из задания
coffee = np.array([1, 1, 2, 2, 2, 2, 3, 3, 3, 4])
score = np.array([85, 88, 79, 81, 84, 65, 67, 58, 76, 49])

print("=" * 80)
print("РАСЧЕТ КОРРЕЛЯЦИИ ПИРСОНА")
print("=" * 80)

print("\nДанные:")
print("Чашки кофе | Балл")
print("-" * 25)
for i in range(len(coffee)):
    print(f"{coffee[i]:10d} | {score[i]:4d}")

# Вычисляем корреляцию
correlation = pearson_correlation(coffee, score)
print("\n" + "=" * 80)
print("ХОД РЕШЕНИЯ:")
print("=" * 80)

print("\n1. Вычисляем средние значения:")
mean_coffee = np.mean(coffee)
mean_score = np.mean(score)
print(f"   Среднее количество чашек кофе: {mean_coffee:.2f}")
print(f"   Средний балл: {mean_score:.2f}")
print("\n2. Вычисляем отклонения от среднего:")
print("   Чашки | Балл | (xi - x̄) | (yi - ȳ) | (xi - x̄)(yi - ȳ)")
print("   " + "-" * 60)
for i in range(len(coffee)):
    diff_x = coffee[i] - mean_coffee
    diff_y = score[i] - mean_score
    product = diff_x * diff_y
    print(f"   {coffee[i]:6d} | {score[i]:4d} | {diff_x:8.2f} | {diff_y:8.2f} | {product:13.2f}")

print("\n3. Вычисляем корреляцию Пирсона:")
numerator = np.sum((coffee - mean_coffee) * (score - mean_score))
sum_sq_diff_coffee = np.sum((coffee - mean_coffee) ** 2)
sum_sq_diff_score = np.sum((score - mean_score) ** 2)
denominator = math.sqrt(sum_sq_diff_coffee * sum_sq_diff_score)
print(f"   Числитель: Σ((xi - x̄)(yi - ȳ)) = {numerator:.2f}")
print(f"   Σ(xi - x̄)² = {sum_sq_diff_coffee:.2f}")
print(f"   Σ(yi - ȳ)² = {sum_sq_diff_score:.2f}")
print(f"   Знаменатель: √(Σ(xi - x̄)² * Σ(yi - ȳ)²) = {denominator:.2f}")
print(f"   r = {numerator:.2f} / {denominator:.2f} = {correlation:.2f}")
print("\n" + "=" * 80)
print(f"КОЭФФИЦИЕНТ КОРРЕЛЯЦИИ ПИРСОНА: {correlation:.2f}")
print("=" * 80)
print("\nИНТЕРПРЕТАЦИЯ:")
print(f"Коэффициент корреляции r = {correlation:.2f}")

if abs(correlation) < 0.3:
    strength = "слабая"
elif abs(correlation) < 0.7:
    strength = "умеренная"
else:
    strength = "сильная"
if correlation < 0:
    direction = "отрицательная"
    print(f"Наблюдается {strength} {direction} корреляция.")
    print("Чем больше чашек кофе, тем ниже балл за экзамен.")
else:
    direction = "положительная"
    print(f"Наблюдается {strength} {direction} корреляция.")
    print("Чем больше чашек кофе, тем выше балл за экзамен.")
    print("\n" + "=" * 80)
print("ВЫВОДЫ О ПРИЧИННО-СЛЕДСТВЕННОЙ СВЯЗИ:")
print("=" * 80)

print("\n❌ НЕТ, нельзя утверждать о причинно-следственной связи на основе корреляции.")
print("\nПричины:")
print("1. Корреляция не означает причинность (correlation ≠ causation)")
print("2. Возможны скрытые переменные:")
print("   - Стресс (высокий стресс → больше кофе + ниже балл)")
print("   - Недостаток сна (недосып → больше кофе + ниже балл)")
print("   - Уровень подготовки (низкая подготовка → больше кофе + ниже балл)")
print("3. Возможна обратная причинность:")
print("   - Низкий балл может вызывать стресс, который приводит к большему потреблению кофе")
print("4. Небольшой размер выборки (n=10) не позволяет делать надежные выводы")
print("5. Могут быть выбросы и другие факторы, влияющие на результат")

print("\nДля установления причинно-следственной связи необходимо:")
print("- Провести контролируемый эксперимент")
print("- Учесть все возможные смешивающие переменные")
print("- Использовать больший размер выборки")
print("- Применить методы причинного вывода (causal inference)")

"""
check
РАСЧЕТ КОРРЕЛЯЦИИ ПИРСОНА
================================================================================

Данные:
Чашки кофе | Балл
-------------------------
         1 |   85
         1 |   88
         2 |   79
         2 |   81
         2 |   84
         2 |   65
         3 |   67
         3 |   58
         3 |   76
         4 |   49

================================================================================
ХОД РЕШЕНИЯ:
================================================================================

1. Вычисляем средние значения:
   Среднее количество чашек кофе: 2.30
   Средний балл: 73.20

2. Вычисляем отклонения от среднего:
   Чашки | Балл | (xi - x̄) | (yi - ȳ) | (xi - x̄)(yi - ȳ)
   ------------------------------------------------------------
        1 |   85 |    -1.30 |    11.80 |        -15.34
        1 |   88 |    -1.30 |    14.80 |        -19.24
        2 |   79 |    -0.30 |     5.80 |         -1.74
        2 |   81 |    -0.30 |     7.80 |         -2.34
        2 |   84 |    -0.30 |    10.80 |         -3.24
        2 |   65 |    -0.30 |    -8.20 |          2.46
        3 |   67 |     0.70 |    -6.20 |         -4.34
        3 |   58 |     0.70 |   -15.20 |        -10.64
        3 |   76 |     0.70 |     2.80 |          1.96
        4 |   49 |     1.70 |   -24.20 |        -41.14

3. Вычисляем корреляцию Пирсона:
   Числитель: Σ((xi - x̄)(yi - ȳ)) = -93.60
   Σ(xi - x̄)² = 8.10
   Σ(yi - ȳ)² = 1499.60
   Знаменатель: √(Σ(xi - x̄)² * Σ(yi - ȳ)²) = 110.21
   r = -93.60 / 110.21 = -0.85

================================================================================
КОЭФФИЦИЕНТ КОРРЕЛЯЦИИ ПИРСОНА: -0.85
================================================================================

ИНТЕРПРЕТАЦИЯ:
Коэффициент корреляции r = -0.85
Наблюдается сильная отрицательная корреляция.
Чем больше чашек кофе, тем ниже балл за экзамен.
ВЫВОДЫ О ПРИЧИННО-СЛЕДСТВЕННОЙ СВЯЗИ:
================================================================================

❌ НЕТ, нельзя утверждать о причинно-следственной связи на основе корреляции.

Причины:
1. Корреляция не означает причинность (correlation ≠ causation)
2. Возможны скрытые переменные:
   - Стресс (высокий стресс → больше кофе + ниже балл)
   - Недостаток сна (недосып → больше кофе + ниже балл)
   - Уровень подготовки (низкая подготовка → больше кофе + ниже балл)
3. Возможна обратная причинность:
   - Низкий балл может вызывать стресс, который приводит к большему потреблению кофе
4. Небольшой размер выборки (n=10) не позволяет делать надежные выводы
5. Могут быть выбросы и другие факторы, влияющие на результат

Для установления причинно-следственной связи необходимо:
- Провести контролируемый эксперимент
- Учесть все возможные смешивающие переменные
- Использовать больший размер выборки
- Применить методы причинного вывода (causal inference)
"""
